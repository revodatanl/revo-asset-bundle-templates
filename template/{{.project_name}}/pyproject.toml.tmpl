[project]
name = "{{.package_name}}"
version = "0.1.0"
description = "{{.description}}"
authors = [
    { name = "{{.author}}", email = "notifications@example.com" },
]
readme = "README.md"
requires-python = {{if not (eq .python_only "yes")}}">=3.11,<4.0"{{else}}">=3.12,<4.0"{{end}}
dependencies = [{{if not (eq .python_only "yes")}}{{if not (eq .use_devcontainer "yes")}}"numpy==1.23.5",  # Databricks Runtime 15.4 LTS
    "pandas==1.5.3",  # Databricks Runtime 15.4 LTS{{end}}
    "pyspark==3.5.0",  # Databricks Runtime 15.4 LTS{{end}}
]

{{if (eq .package_manager "uv")}}[tool.uv]
package = true
dev-dependencies = [
    "bandit>=1.8.3",{{if not (eq .python_only "yes")}}
    "databricks-dlt==0.2.1",  # Pinned at 0.2.1 since higher versions depend on databricks-connect 11.3+
    "databricks-sdk>=0.45.0",{{end}}
    "mkdocs-material>=9.6.7",
    "mkdocs>=1.6.1",
    "mypy>=1.15.0",
    "pdoc3>=0.11.5",
    "pre-commit>=4.1.0",
    "pydoclint>=0.5.8",
    "pytest-cov>=6.0.0",
    "pytest-mock>=3.14.0",
    "pytest>=8.3.5",
    "ruff>=0.9.10",
    "sqlfluff>=3.3.1",
]

[project.scripts]
main = "{{.package_name}}.main:main"{{else}}[tool.poetry]
classifiers = ["Programming Language :: Python :: {{if not (eq .python_only "yes")}}3.11{{else}}3.12{{end}}", "Operating System :: OS Independent"]
packages = [{ include = "{{.package_name}}", from = "src" }]

[tool.poetry.scripts]
main = "{{.package_name}}.main:main"

[tool.poetry.group.dev.dependencies]
bandit = "^1.7.10"{{if not (eq .python_only "yes")}}
databricks-dlt = "0.2.1"  # Pinned at 0.2.1 since higher versions depend on databricks-connect 11.3+
databricks-sdk = "^0.45.0"{{end}}
mkdocs = "^1.6.1"
mkdocs-material = "^9.6.7"
mypy = "^1.13.0"
pdoc3 = "^0.11.1"
pre-commit = "^4.0.1"
pydoclint = "^0.5.8"
pytest = "^8.3.5"
pytest-cov = "^6.0.0"
pytest-mock = "^3.14.0"
ruff = "^0.9.10"
sqlfluff = "^3.2.5"

{{if not (eq .python_only "yes")}}
[tool.poetry.group.types.dependencies]
pandas-stubs = "^2.2.2.240807"  # Databricks Runtime 15.4 LTS
{{end}}
{{end}}
{{if (eq .package_manager "poetry")}}[build-system]
requires = ["poetry-core>=2.0"]
build-backend = "poetry.core.masonry.api"{{end}}

[tool.ruff]
target-version = {{if not (eq .python_only "yes")}}"py311"{{else}}"py312"{{end}}
line-length = 100
extend-include = ["*.ipynb"]
extend-exclude = ["scratch"]
builtins = ["dbutils", "display", "spark"]

[tool.ruff.lint]
pydocstyle.convention = "numpy"
external = ["DOC"]
select = ["ALL"]
ignore = [
    "D203",     # "One blank line required before class docstring." Should be disabled by default.
    "D213",     # "Multi-line docstring summary should start at the second line." Should be disabled by default.
    "E501",     # "Line too long." Sometimes my comments are a bit longer.
    "E731",     # "Do not assign a lambda expression, use a def." Needed for spark UDFs.
    "ERA001",   # "Found commented out code."
    "FBT001",   # "Boolean positional arg in function definition.
    "FBT002",   # "Boolean default value in function definition."
    "FBT003",   # "Boolean positional value in function call." This is common in spark.
    "ISC001",   # "Implicit string concatenation." Ignored since it conflicts with the formatter.
    "N812",     # "Lowercase `functions` imported as non-lowercase." Pretty standard for spark programming.
    "T201",     # "`print` found."
    # Nitpicky exceptions - comment out when productionalizing your code
    "BLE001",   # Do not catch blind exception: `Exception`
    "D400",     # First line should end with a period
    "D401",     # First line of docstring should be in imperative mood
    "PD901",    # Avoid using the generic variable name `df` for DataFrames
    "PLR2004",  # "Magic value used in comparison, consider replacing with a constant variable."
    "TRY003"    #  Avoid specifying long messages outside the exception class
]
unfixable = [
    "F401",     # "Unused import." Disabled since it makes linting/formatting notebooks messy and impossible.
]

[tool.ruff.lint.per-file-ignores]
"notebooks/**/*.py" = [
    "D100",     # "Missing docstring in public module." Not needed for Databricks notebooks.
    "INP001",   # "Part of an implicit namespace package. Add an `__init__.py`." Not needed for Databricks notebooks.
]
"tests/*.py" = [
    "PLR2004",  # "Magic value used in comparison, consider replacing with a constant variable."
    "S101",     # "Use of `assert` detected."

]

[tool.mypy]
python_version = {{if not (eq .python_only "yes")}}"3.11"{{else}}"3.12"{{end}}
mypy_path = ["src", ".vscode"]
strict = true
disallow_untyped_decorators = false
exclude = "scratch"

[[tool.mypy.overrides]]
module = ["dbutils", "display", "spark"]
ignore_missing_imports = true
disable_error_code = "name-defined"

[tool.pytest.ini_options]
testpaths = ["tests"]
pythonpath = ["src"]

[tool.pydoclint]
style = "numpy"
exclude = ".git|.venv|scratch"

[tool.bandit]
targets = ["src"]
skips = []
exclude_dirs = [".venv", "archive", "scratch", "tests"]

[tool.sqlfluff.core]
dialect = "databricks"
templater = "jinja"
max_line_length = 120
ignore = "parsing"

[tool.sqlfluff.indentation]
indented_joins = false
indented_using_on = true
template_blocks_indent = false

[tool.sqlfluff.rules.capitalisation.keywords]
capitalisation_policy = "upper"
