name: CI DABs

on:
  pull_request:
    types: [opened, synchronize, reopened]
  workflow_dispatch:

jobs:
  ci-dabs:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        include:
          # Default configurations
          - os: ubuntu-latest
            cicd_provider: github
            cloud_provider: azure
            include_example_jobs: yes
          - os: macos-latest
            cicd_provider: github
            cloud_provider: azure
            include_example_jobs: yes
          # Non-default configuration
          - os: ubuntu-latest
            cicd_provider: azure
            cloud_provider: aws
            include_example_jobs: no
          - os: macos-latest
            cicd_provider: azure
            cloud_provider: aws
            include_example_jobs: no

    env:
      BRANCH_NAME: ${{ github.head_ref || github.ref_name }}

    steps:
      - name: Install Databricks CLI
        run: |
          curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sudo sh
          databricks --version

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          uv --version

      - name: Create init parameters JSON
        run: |
          cat > init_params.json << EOF
          {
            "project_name": "revo-dabs-test-project",
            "author": "Thomas Brouwer",
            "email": "thomas.brouwer@revodata.nl",
            "project_description": "This project is generated using our own RevoData Asset Bundle Templates.",
            "cicd_provider": "${{ matrix.cicd_provider }}",
            "cloud_provider": "${{ matrix.cloud_provider }}",
            "include_example_jobs": "${{ matrix.include_example_jobs }}"
          }
          EOF
          cat init_params.json

      - name: Initialize Databricks Asset Bundle from template
        run: |
          echo "Using branch: $BRANCH_NAME"
          databricks bundle init https://github.com/revodatanl/revo-asset-bundle-templates --branch $BRANCH_NAME --config-file init_params.json
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_CLIENT_ID: ${{ secrets.DATABRICKS_CLIENT_ID }}
          DATABRICKS_CLIENT_SECRET: ${{ secrets.DATABRICKS_CLIENT_SECRET }}

      - name: Build and test Databricks Asset Bundle with Makefile
        run: |
          cd revo-dabs-test-project
          echo ""
          echo "=================================================================="
          echo "=============== BUILD PROJECT (WITH DEFAULT TARGET) =============="
          echo "=================================================================="
          make

          echo ""
          echo "=================================================================="
          echo "=============== RE-BUILD PROJECT (WITH SETUP TARGET) ============="
          echo "=================================================================="
          make setup

          echo ""
          echo "=================================================================="
          echo "==================== COMMIT ALL FILES ============================"
          echo "=================================================================="
          uv run pre-commit autoupdate || true
          git config --global user.email "pipeline@github.com"
          git config --global user.name "GitHub Actions"
          git add .
          git commit -m "feat: initial commit"

          echo ""
          echo "=================================================================="
          echo "======================== LINT PROJECT ============================"
          echo "=================================================================="
          make lint

          echo ""
          echo "=================================================================="
          echo "========================= RUN TESTS =============================="
          echo "=================================================================="
          make test


          echo ""
          echo "=================================================================="
          echo "======================== CLEAN PROJECT ==========================="
          echo "=================================================================="
          make clean

          echo ""
          echo "=================================================================="
          echo "================ RE-BUILD PROJECT (AFTER CLEAN) =================="
          echo "=================================================================="
          make

          echo ""
          echo "=================================================================="
          echo "======================== UPDATE TARGETS =========================="
          echo "=================================================================="
          make update

          echo ""
          echo "=================================================================="
          echo "======================== VALIDATE BUNDLE ========================="
          echo "=================================================================="
          databricks bundle validate
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_CLIENT_ID: ${{ secrets.DATABRICKS_CLIENT_ID }}
          DATABRICKS_CLIENT_SECRET: ${{ secrets.DATABRICKS_CLIENT_SECRET }}


      # - name: Deploy Databricks Asset Bundle (using default runner only)
      #   if: |
      #     matrix.os == 'ubuntu-latest' &&
      #     matrix.cicd_provider == 'github' &&
      #     matrix.cloud_provider == 'azure' &&
      #     matrix.include_example_jobs == 'yes'
      #   run: |
      #     cd revo-dabs-test-project
      #     echo ""
      #     echo "=================================================================="
      #     echo "======================== DEPLOY BUNDLE ==========================="
      #     echo "=================================================================="
      #     databricks bundle deploy
      #   env:
      #     DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      #     DATABRICKS_CLIENT_ID: ${{ secrets.DATABRICKS_CLIENT_ID }}
      #     DATABRICKS_CLIENT_SECRET: ${{ secrets.DATABRICKS_CLIENT_SECRET }}

      # - name: Upload project artifact
      #   if: |
      #     matrix.os == 'ubuntu-latest' &&
      #     matrix.cicd_provider == 'github' &&
      #     matrix.cloud_provider == 'azure' &&
      #     matrix.include_example_jobs == 'yes'
      #   uses: actions/upload-artifact@v4
      #   with:
      #     name: revo-dabs-test-project
      #     path: revo-dabs-test-project
      #     retention-days: 1


#   run-example-job:
#     needs: ci-dabs
#     if: success()
#     runs-on: ubuntu-latest
#     steps:
#       - name: Download project artifact
#         uses: actions/download-artifact@v4
#         with:
#           name: revo-dabs-test-project
#           path: revo-dabs-test-project

#       - name: Install Databricks CLI
#         run: |
#           curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sudo sh
#           databricks version

#       - name: Run Example Job
#         run: |
#           cd revo-dabs-test-project
#           echo ""
#           echo "=================================================================="
#           echo "======================== RUN EXAMPLE JOB ========================="
#           echo "=================================================================="
#           echo "Starting 'example-job' job... (this may take a while)"
#           EXAMPLE_JOB_ID=$(databricks jobs list --output json | jq '.[] | select(.settings.name | contains("example-job")) | .job_id')
#           echo "Example job ID: $EXAMPLE_JOB_ID"

#           if [ -z "$EXAMPLE_JOB_ID" ]; then
#             echo "Error: Could not find example-job"
#             databricks jobs list --output text
#             exit 1
#           fi

#           RESULT_STATE=$(databricks jobs run-now $EXAMPLE_JOB_ID | jq -r '.state.result_state')
#           echo "Job result state: $RESULT_STATE"

#           if [[ "$RESULT_STATE" == "SUCCESS" ]]; then
#             echo "Job completed successfully!"
#           else
#             echo "Job failed with status: $RESULT_STATE"
#             exit 1
#           fi
#         env:
#           DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
#           DATABRICKS_CLIENT_ID: ${{ secrets.DATABRICKS_CLIENT_ID }}
#           DATABRICKS_CLIENT_SECRET: ${{ secrets.DATABRICKS_CLIENT_SECRET }}


#   run-example-pipeline-job:
#     needs: ci-dabs
#     if: success()
#     runs-on: ubuntu-latest
#     steps:
#       - name: Download project artifact
#         uses: actions/download-artifact@v4
#         with:
#           name: revo-dabs-test-project
#           path: revo-dabs-test-project

#       - name: Install Databricks CLI
#         run: |
#           curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sudo sh
#           databricks version

#       - name: Run example pipeline job
#         run: |
#           cd revo-dabs-test-project
#           echo ""
#           echo "=================================================================="
#           echo "================ RUN EXAMPLE PIPELINE JOB ========================"
#           echo "=================================================================="
#           echo "Starting 'example-pipeline-job'... (this may take a while)"
#           PIPELINE_JOB_ID=$(databricks jobs list --output json | jq '.[] | select(.settings.name | contains("example-pipeline-job")) | .job_id')
#           echo "Pipeline job ID: $PIPELINE_JOB_ID"

#           if [ -z "$PIPELINE_JOB_ID" ]; then
#             echo "Error: Could not find example-pipeline-job"
#             databricks jobs list --output text
#             exit 1
#           fi

#           PIPELINE_RESULT_STATE=$(databricks jobs run-now $PIPELINE_JOB_ID | jq -r '.state.result_state')
#           echo "Pipeline result state: $PIPELINE_RESULT_STATE"

#           if [[ "$PIPELINE_RESULT_STATE" == "SUCCESS" ]]; then
#             echo "Pipeline job completed successfully!"
#           else
#             echo "Pipeline job failed with status: $PIPELINE_RESULT_STATE"
#             exit 1
#           fi
#         env:
#           DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
#           DATABRICKS_CLIENT_ID: ${{ secrets.DATABRICKS_CLIENT_ID }}
#           DATABRICKS_CLIENT_SECRET: ${{ secrets.DATABRICKS_CLIENT_SECRET }}


# # Destroy bundle regardless of the outcome of both jobs
#   destroy-bundle:
#     needs: [run-example-job, run-example-pipeline-job]
#     if: always()
#     runs-on: ubuntu-latest
#     steps:
#       - name: Download project artifact
#         uses: actions/download-artifact@v4
#         with:
#           name: revo-dabs-test-project
#           path: revo-dabs-test-project

#       - name: Install Databricks CLI
#         run: |
#           curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sudo sh
#           databricks version

#       - name: Destroy Bundle
#         run: |
#           cd revo-dabs-test-project
#           echo ""
#           echo "=================================================================="
#           echo "======================== DESTROY BUNDLE =========================="
#           echo "=================================================================="
#           databricks bundle destroy --auto-approve
#         env:
#           DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
#           DATABRICKS_CLIENT_ID: ${{ secrets.DATABRICKS_CLIENT_ID }}
#           DATABRICKS_CLIENT_SECRET: ${{ secrets.DATABRICKS_CLIENT_SECRET }}
