name: CI DABs

on:
  pull_request:
    types: [opened, synchronize, reopened]

jobs:
  ci-dabs:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        include:
          # Default configurations
          - os: ubuntu-latest
            cicd_provider: github
            cloud_provider: azure
            include_example_jobs: yes
            include_devcontainer: no
          - os: macos-latest
            cicd_provider: github
            cloud_provider: azure
            include_example_jobs: yes
            include_devcontainer: no
          # Non-default configuration
          - os: ubuntu-latest
            cicd_provider: azure
            cloud_provider: aws
            include_example_jobs: no
            include_devcontainer: yes
          - os: macos-latest
            cicd_provider: azure
            cloud_provider: aws
            include_example_jobs: no
            include_devcontainer: yes

    env:
      BRANCH_NAME: ${{ github.head_ref }}

    steps:
      - name: Install Databricks CLI
        run: |
          curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sudo sh
          databricks version

      - name: Create init parameters JSON
        run: |
          cat > init_params.json << EOF
          {
            "project_name": "revo-dabs-test-project",
            "package_name": "revo_dabs",
            "author": "Thomas Brouwer",
            "email": "thomas.brouwer@revodata.nl",
            "project_description": "This project is generated using our own RevoData Asset Bundle Templates.",
            "cicd_provider": "${{ matrix.cicd_provider }}",
            "cloud_provider": "${{ matrix.cloud_provider }}",
            "include_example_jobs": "${{ matrix.include_example_jobs }}",
            "include_devcontainer": "${{ matrix.include_devcontainer }}"
          }
          EOF
          cat init_params.json

      - name: Initialize Databricks Asset Bundle from template
        run: |
          echo "Using branch: $BRANCH_NAME"
          databricks bundle init https://github.com/revodatanl/revo-asset-bundle-templates --branch $BRANCH_NAME --config-file init_params.json
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_CLIENT_ID: ${{ secrets.DATABRICKS_CLIENT_ID }}
          DATABRICKS_CLIENT_SECRET: ${{ secrets.DATABRICKS_CLIENT_SECRET }}

      - name: Build and test Databricks Asset Bundle with Makefile
        run: |
          cd revo-dabs-test-project
          echo ""
          echo "=================================================================="
          echo "=============== BUILD PROJECT (WITH DEFAULT TARGET) =============="
          echo "=================================================================="
          make

          echo ""
          echo "=================================================================="
          echo "=============== RE-INSTALL DEPENDENCIES ========================="
          echo "=================================================================="
          make install

          echo ""
          echo "=================================================================="
          echo "=============== RE-BUILD PROJECT (WITH SETUP TARGET) ============="
          echo "=================================================================="
          make setup

          echo ""
          echo "=================================================================="
          echo "======================== GENERATE TREE ==========================="
          echo "=================================================================="
          make tree

          echo ""
          echo "=================================================================="
          echo "======================== LINT PROJECT ============================"
          echo "=================================================================="
          make lint

          echo ""
          echo "=================================================================="
          echo "========================= RUN TESTS =============================="
          echo "=================================================================="
          make test

          echo ""
          echo "=================================================================="
          echo "======================== GENERATE DOCS ==========================="
          echo "=================================================================="
          uv run mkdocs build

          echo ""
          echo "=================================================================="
          echo "======================== CLEAN PROJECT ==========================="
          echo "=================================================================="
          make clean

          echo ""
          echo "=================================================================="
          echo "=========== RE-BUILD PROJECT (AFTER CLEAN) ======================="
          echo "=================================================================="
          make

          echo ""
          echo "=================================================================="
          echo "======================== VALIDATE BUNDLE ========================="
          echo "=================================================================="
          databricks bundle validate
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_CLIENT_ID: ${{ secrets.DATABRICKS_CLIENT_ID }}
          DATABRICKS_CLIENT_SECRET: ${{ secrets.DATABRICKS_CLIENT_SECRET }}

      - name: Deploy Databricks Asset Bundle (using default runner only)
        if: |
          matrix.os == 'ubuntu-latest' &&
          matrix.cicd_provider == 'github' &&
          matrix.cloud_provider == 'azure' &&
          matrix.include_example_jobs == 'yes' &&
          matrix.include_devcontainer == 'no'
        run: |
          cd revo-dabs-test-project
          echo ""
          echo "=================================================================="
          echo "======================== DEPLOY BUNDLE ==========================="
          echo "=================================================================="
          databricks bundle deploy
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_CLIENT_ID: ${{ secrets.DATABRICKS_CLIENT_ID }}
          DATABRICKS_CLIENT_SECRET: ${{ secrets.DATABRICKS_CLIENT_SECRET }}

      - name: Upload project artifact
        if: |
          matrix.os == 'ubuntu-latest' &&
          matrix.cicd_provider == 'github' &&
          matrix.cloud_provider == 'azure' &&
          matrix.include_example_jobs == 'yes' &&
          matrix.include_devcontainer == 'no'
        uses: actions/upload-artifact@v4
        with:
          name: revo-dabs-test-project
          path: revo-dabs-test-project
          retention-days: 1


# Run example workflow in parallel with the example DLT pipeline workflow
  run-example-workflow:
    needs: ci-dabs
    if: success()
    runs-on: ubuntu-latest
    steps:
      - name: Download project artifact
        uses: actions/download-artifact@v4
        with:
          name: revo-dabs-test-project
          path: revo-dabs-test-project

      - name: Install Databricks CLI
        run: |
          curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sudo sh
          databricks version

      - name: Run Example Workflow
        run: |
          cd revo-dabs-test-project
          echo ""
          echo "=================================================================="
          echo "==================== RUN EXAMPLE WORKFLOW ========================"
          echo "=================================================================="
          echo "Starting 'example-workflow'... (this may take a while)"
          EXAMPLE_WORKFLOW_ID=$(databricks jobs list --output json | jq '.[] | select(.settings.name | contains("example-workflow")) | .job_id')
          echo "Example workflow ID: $EXAMPLE_WORKFLOW_ID"
          RESULT_STATE=$(databricks jobs run-now $EXAMPLE_WORKFLOW_ID | jq -r '.state.result_state')
          echo "Workflow result state: $RESULT_STATE"

          if [[ "$RESULT_STATE" == "SUCCESS" ]]; then
            echo "Workflow completed successfully!"
          else
            echo "Workflow failed with status: $RESULT_STATE"
            exit 1
          fi
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_CLIENT_ID: ${{ secrets.DATABRICKS_CLIENT_ID }}
          DATABRICKS_CLIENT_SECRET: ${{ secrets.DATABRICKS_CLIENT_SECRET }}


# Run example DLT pipeline workflow in parallel with the example workflow
  run-example-dlt-workflow:
    needs: ci-dabs
    if: success()
    runs-on: ubuntu-latest
    steps:
      - name: Download project artifact
        uses: actions/download-artifact@v4
        with:
          name: revo-dabs-test-project
          path: revo-dabs-test-project

      - name: Install Databricks CLI
        run: |
          curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sudo sh
          databricks version

      - name: Run example DLT pipeline workflow
        run: |
          cd revo-dabs-test-project
          echo ""
          echo "=================================================================="
          echo "=============== RUN EXAMPLE DLT PIPELINE WORKFLOW ================"
          echo "=================================================================="
          echo "Starting 'example-dlt-pipeline-workflow'... (this may take a while)"
          DLT_PIPELINE_WORKFLOW_ID=$(databricks jobs list --output json | jq '.[] | select(.settings.name | contains("example-dlt-pipeline-workflow")) | .job_id')
          echo "Example DLT pipeline ID: $DLT_PIPELINE_WORKFLOW_ID"
          DLT_PIPELINE_WORKFLOW_RESULT_STATE=$(databricks jobs run-now $DLT_PIPELINE_WORKFLOW_ID | jq -r '.state.result_state')
          echo "DLT pipeline result state: $DLT_PIPELINE_WORKFLOW_RESULT_STATE"

          if [[ "$DLT_PIPELINE_WORKFLOW_RESULT_STATE" == "SUCCESS" ]]; then
            echo "DLT pipeline completed successfully!"
          else
            echo "DLT pipeline failed with status: $DLT_PIPELINE_RESULT_STATE"
            exit 1
          fi
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_CLIENT_ID: ${{ secrets.DATABRICKS_CLIENT_ID }}
          DATABRICKS_CLIENT_SECRET: ${{ secrets.DATABRICKS_CLIENT_SECRET }}


# Destroy bundle regardless of the outcome of the other workflows
  destroy-bundle:
    needs: [run-example-workflow, run-example-dlt-workflow]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Download project artifact
        uses: actions/download-artifact@v4
        with:
          name: revo-dabs-test-project
          path: revo-dabs-test-project

      - name: Install Databricks CLI
        run: |
          curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sudo sh
          databricks version

      - name: Destroy Bundle
        run: |
          cd revo-dabs-test-project
          echo ""
          echo "=================================================================="
          echo "======================== DESTROY BUNDLE =========================="
          echo "=================================================================="
          databricks bundle destroy --auto-approve
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_CLIENT_ID: ${{ secrets.DATABRICKS_CLIENT_ID }}
          DATABRICKS_CLIENT_SECRET: ${{ secrets.DATABRICKS_CLIENT_SECRET }}
